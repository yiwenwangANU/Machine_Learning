{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow Certificate Model 0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMCOsnnGI8d6Cv21ojxzWid",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yiwenwangANU/Machine_Learning/blob/main/Tensorflow_Certificate_Model_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data"
      ],
      "metadata": {
        "id": "o0r_HxCC4FcJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "jZRvDZNYxOJs"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "metadata": {
        "id": "UYgw4fcDx8sR"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(path_to_file, 'rb') as f:\n",
        "  raw_data = f.read().decode('utf-8')"
      ],
      "metadata": {
        "id": "RtDqTY7WyAY_"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = list(set(raw_data))\n",
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5eUFNO7yMjx",
        "outputId": "ab884cc5-9ae3-4ba5-f656-838e3195b202"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_chars = tf.strings.unicode_split(raw_data, input_encoding='UTF-8')\n",
        "all_chars[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8Y1nblmyOKG",
        "outputId": "a9e48ad1-f9a8-428d-c27a-b3f265c8397c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(100,), dtype=string, numpy=\n",
              "array([b'F', b'i', b'r', b's', b't', b' ', b'C', b'i', b't', b'i', b'z',\n",
              "       b'e', b'n', b':', b'\\n', b'B', b'e', b'f', b'o', b'r', b'e', b' ',\n",
              "       b'w', b'e', b' ', b'p', b'r', b'o', b'c', b'e', b'e', b'd', b' ',\n",
              "       b'a', b'n', b'y', b' ', b'f', b'u', b'r', b't', b'h', b'e', b'r',\n",
              "       b',', b' ', b'h', b'e', b'a', b'r', b' ', b'm', b'e', b' ', b's',\n",
              "       b'p', b'e', b'a', b'k', b'.', b'\\n', b'\\n', b'A', b'l', b'l', b':',\n",
              "       b'\\n', b'S', b'p', b'e', b'a', b'k', b',', b' ', b's', b'p', b'e',\n",
              "       b'a', b'k', b'.', b'\\n', b'\\n', b'F', b'i', b'r', b's', b't', b' ',\n",
              "       b'C', b'i', b't', b'i', b'z', b'e', b'n', b':', b'\\n', b'Y', b'o',\n",
              "       b'u'], dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars_to_ids = layers.StringLookup(vocabulary=vocab)\n",
        "ids_to_chars = layers.StringLookup(vocabulary=chars_to_ids.get_vocabulary(), invert=True)\n",
        "all_ids = chars_to_ids(all_chars)\n",
        "all_ids[:100],len(all_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kp2s3ihnzBVF",
        "outputId": "380d2886-ecd4-4c65-fd34-7817d28d6f82"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
              " array([ 6, 48, 52, 37, 31, 43, 22, 48, 31, 48, 39, 58,  8, 12, 36, 18, 58,\n",
              "        57, 59, 52, 58, 43, 44, 58, 43, 17, 52, 59,  5, 58, 58, 62, 43, 28,\n",
              "         8, 35, 43, 57, 29, 52, 31, 23, 58, 52, 49, 43, 23, 58, 28, 52, 43,\n",
              "        27, 58, 43, 37, 17, 58, 28, 53,  2, 36, 36, 46, 42, 42, 12, 36, 24,\n",
              "        17, 58, 28, 53, 49, 43, 37, 17, 58, 28, 53,  2, 36, 36,  6, 48, 52,\n",
              "        37, 31, 43, 22, 48, 31, 48, 39, 58,  8, 12, 36, 26, 59, 29])>, 1115394)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
        "ids_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvlEiMAczgo6",
        "outputId": "49afbe7c-356f-44ae-f6fd-6ef13e92ab21"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100\n",
        "batched_dataset = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "batched_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znR8fT611Wt7",
        "outputId": "d3bf159c-cd40-4939-aa10-d11b7e226809"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=TensorSpec(shape=(101,), dtype=tf.int64, name=None)>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def input_target_split(sequence):\n",
        "  return sequence[:-1], sequence[1:]"
      ],
      "metadata": {
        "id": "aEA3H3wa2Wqb"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = batched_dataset.map(input_target_split)\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jKrDms72wKe",
        "outputId": "a0e0a173-e035-4e82-886b-a74dcf6fd579"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<MapDataset element_spec=(TensorSpec(shape=(100,), dtype=tf.int64, name=None), TensorSpec(shape=(100,), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, target in dataset.take(1):\n",
        "  print(tf.strings.reduce_join(ids_to_chars(inputs)))\n",
        "  print(tf.strings.reduce_join(ids_to_chars(target)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxB4v2zC3IvQ",
        "outputId": "3a838ee0-6b97-4090-a599-54a63eef1302"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou', shape=(), dtype=string)\n",
            "tf.Tensor(b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou ', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###############################forget###############################\n",
        "prefetched_dataset = dataset.batch(64).prefetch(tf.data.AUTOTUNE) \n",
        "prefetched_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bj_HcMpy8Swr",
        "outputId": "3e8047f7-52b6-40e4-8bf2-c304b2d932ce"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 100), dtype=tf.int64, name=None), TensorSpec(shape=(None, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "3WY6Eu_f3hgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(chars_to_ids.get_vocabulary())\n",
        "embedding_dims = 256\n",
        "rnn_units = 1024"
      ],
      "metadata": {
        "id": "jtikMXFV5IFi"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model_0(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dims, rnn_units):\n",
        "        super(Model_0, self).__init__()\n",
        "        self.embed = layers.Embedding(input_dim=vocab_size,\n",
        "                                      output_dim=embedding_dims,\n",
        "                                      name='embed')\n",
        "        self.GRU = layers.GRU(units=rnn_units, ###############################?????###############################\n",
        "                                return_sequences=True,\n",
        "                                return_state=True,\n",
        "                                name='GRU')\n",
        "        self.Dense = layers.Dense(units=vocab_size, name='Dense')\n",
        "\n",
        "    def call(self, inputs, return_state=False, state=None):\n",
        "        x = self.embed(inputs)  #(batch, 100, embed)\n",
        "        if(state==None):\n",
        "          state = self.GRU.get_initial_state(x)\n",
        "        x, state = self.GRU(x, initial_state=state)  #(batch, seq, vocab)\n",
        "        outputs = self.Dense(x)\n",
        "        if(return_state==True):\n",
        "          return outputs, state\n",
        "        else:\n",
        "          return outputs\n"
      ],
      "metadata": {
        "id": "41WlftYk4HwJ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model_0(vocab_size=vocab_size,\n",
        "                embedding_dims=embedding_dims,\n",
        "                rnn_units=rnn_units)"
      ],
      "metadata": {
        "id": "XAJ3yJei7xdr"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, _ in prefetched_dataset.take(1):\n",
        "  print(tf.strings.reduce_join(ids_to_chars(inputs[0])))\n",
        "  ###############################forget###############################\n",
        "  predicted_ids = tf.squeeze(tf.random.categorical(model(inputs)[0], 1))\n",
        "  print(tf.strings.reduce_join(ids_to_chars(predicted_ids)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byv8j-Kg7cJr",
        "outputId": "548f09bb-47f7-4021-c51f-a7613794b3a5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou', shape=(), dtype=string)\n",
            "tf.Tensor(b\"$3rvch'UeFUS3-.OF!H$rsyQMvyTZwIZTo3!XBkupzFXqW3:q'E.l,!OitVkQ;rs'R'w,hCVtY-lgpRtlnFQhTIhbnQFVK!bCH.B\", shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam())"
      ],
      "metadata": {
        "id": "gIyGov807__r"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(prefetched_dataset,\n",
        "                    epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foUInOcoGQOr",
        "outputId": "aa46ae78-19cd-4472-a653-d53095b9461a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "173/173 [==============================] - 11s 56ms/step - loss: 2.7442\n",
            "Epoch 2/20\n",
            "173/173 [==============================] - 10s 59ms/step - loss: 2.0760\n",
            "Epoch 3/20\n",
            "173/173 [==============================] - 10s 59ms/step - loss: 1.8318\n",
            "Epoch 4/20\n",
            "173/173 [==============================] - 11s 61ms/step - loss: 1.6655\n",
            "Epoch 5/20\n",
            "173/173 [==============================] - 10s 59ms/step - loss: 1.5454\n",
            "Epoch 6/20\n",
            "173/173 [==============================] - 10s 59ms/step - loss: 1.4589\n",
            "Epoch 7/20\n",
            "173/173 [==============================] - 10s 59ms/step - loss: 1.3951\n",
            "Epoch 8/20\n",
            "173/173 [==============================] - 10s 56ms/step - loss: 1.3429\n",
            "Epoch 9/20\n",
            "173/173 [==============================] - 10s 56ms/step - loss: 1.2963\n",
            "Epoch 10/20\n",
            "173/173 [==============================] - 10s 56ms/step - loss: 1.2519\n",
            "Epoch 11/20\n",
            "173/173 [==============================] - 10s 60ms/step - loss: 1.2073\n",
            "Epoch 12/20\n",
            "173/173 [==============================] - 10s 58ms/step - loss: 1.1600\n",
            "Epoch 13/20\n",
            "173/173 [==============================] - 10s 56ms/step - loss: 1.1100\n",
            "Epoch 14/20\n",
            "173/173 [==============================] - 10s 56ms/step - loss: 1.0596\n",
            "Epoch 15/20\n",
            "173/173 [==============================] - 11s 62ms/step - loss: 1.0172\n",
            "Epoch 16/20\n",
            "173/173 [==============================] - 11s 64ms/step - loss: 0.9832\n",
            "Epoch 17/20\n",
            "173/173 [==============================] - 11s 61ms/step - loss: 0.9549\n",
            "Epoch 18/20\n",
            "173/173 [==============================] - 10s 59ms/step - loss: 0.9264\n",
            "Epoch 19/20\n",
            "173/173 [==============================] - 10s 56ms/step - loss: 0.8950\n",
            "Epoch 20/20\n",
            "173/173 [==============================] - 10s 57ms/step - loss: 0.8727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, _ in prefetched_dataset.take(1):\n",
        "  print(tf.strings.reduce_join(ids_to_chars(inputs[0])))\n",
        "  predicted_ids = tf.squeeze(tf.random.categorical(model(inputs)[0], 1))\n",
        "  print(tf.strings.reduce_join(ids_to_chars(predicted_ids)))"
      ],
      "metadata": {
        "id": "QfH7VlpAGa_G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caf56d0a-c217-4452-aaa2-5d598649389a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou', shape=(), dtype=string)\n",
            "tf.Tensor(b'Frst Gotizen:\\nWecore;tenfeeveed isd ourther  yoad me speak.\\n\\nBNl:\\ngaeak  gpeak \\n\\nBLrst Citizen:\\nAou ', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs='ROMEO:'\n",
        "#()\n",
        "input_ids = chars_to_ids(tf.strings.unicode_split(inputs, input_encoding='UTF-8')) #(seq)\n",
        "output, state = model(tf.expand_dims(input_ids,axis=0), return_state=True) #(batch, seq, vocab)\n",
        "output = tf.squeeze(output, axis=0) #(seq, vocab)\n",
        "pred_ids = tf.squeeze(tf.random.categorical(output, 1), axis=-1) #(seq)\n",
        "pred_chars = ids_to_chars(pred_ids)  #(seq)\n",
        "last_char = pred_chars[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GB0LB6TeKZaW",
        "outputId": "e5ff01a2-f7c5-4aed-aba7-150e6286ce45"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(6,), dtype=string, numpy=array([b'I', b'M', b'E', b'O', b':', b'\\n'], dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(model=model, inputs='ROMEO:', state=None):\n",
        "  input_ids = chars_to_ids(tf.strings.unicode_split(inputs, input_encoding='UTF-8')) #(seq)\n",
        "  output, state = model(tf.expand_dims(input_ids,axis=0),\n",
        "                        return_state=True,\n",
        "                        state=state) #(batch, seq, vocab)  ###############################forget###############################\n",
        "  output = tf.squeeze(output, axis=0) #(seq, vocab)\n",
        "  pred_ids = tf.squeeze(tf.random.categorical(output, 1), axis=-1) #(seq)\n",
        "  pred_chars = ids_to_chars(pred_ids)  #(seq)\n",
        "  next_word = pred_chars[-1]\n",
        "  return next_word, state"
      ],
      "metadata": {
        "id": "847b1M8pG7EP"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_next_word(inputs='R')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Na4kKiX1MsUb",
        "outputId": "dd2e3883-b24d-483e-d4df-01accd426e25"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=string, numpy=b'E'>,\n",
              " <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=\n",
              " array([[ 0.16130322,  0.32743314,  0.11106565, ..., -0.34415296,\n",
              "          0.6390653 ,  0.0230303 ]], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_prediction(model=model, initial_inputs='ROMEO:', state=None, steps=1000):\n",
        "  output = [initial_inputs]\n",
        "  next_word=initial_inputs\n",
        "  for i in range(steps):\n",
        "    next_word, state = predict_next_word(inputs=next_word,\n",
        "                                         state=state)\n",
        "    output.append(next_word)\n",
        "  return tf.strings.reduce_join(output)"
      ],
      "metadata": {
        "id": "971la0A3M2J5"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = make_prediction()\n",
        "print(predictions.numpy().decode('utf-8'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOb-kziiOXGB",
        "outputId": "83375c4a-bc47-49bb-ec38-4aca8a4ed372"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "Here is every man of his good sweet Manacl; is, there diest\n",
            "Into the mirthwation of a book;\n",
            "And if I warrant thee, hortensio has needful,\n",
            "the cedral at the ganey a fet your wedding-day.\n",
            "Borrog and Serioved villain!\n",
            "\n",
            "WARWICK:\n",
            "When I show 'tis for traimon! nay, the tymant's chamber; oath\n",
            "in field up seeds how her not to denied.\n",
            "\n",
            "PETRUCHIO:\n",
            "The bridegroom young Word, do you know her father trembling dark,\n",
            "And woman'd loss she ampured saking.\n",
            "\n",
            "ANTONIO:\n",
            "A Gedler, dream'd!\n",
            "\n",
            "a pieck of reason,\n",
            "Five suste think it the moon shines for thee, for thou say'st o' the tyrant.\n",
            "\n",
            "First Servant:\n",
            "Patience!\n",
            "\n",
            "AUTOLYCUS:\n",
            "Well, for, ere we may paintly?\n",
            "\n",
            "BRUTUS:\n",
            "Go too! of such affair!\n",
            "\n",
            "KATHARINA:\n",
            "Tark here, my son cell the duke as Vardial?\n",
            "\n",
            "KATHARINA:\n",
            "What is't your dute?\n",
            "\n",
            "CLAUDOO:\n",
            "O, ale! am Conquest there?\n",
            "\n",
            "Pedant:\n",
            "She will get she went discontinent\n",
            "But might suit: determine!\n",
            "\n",
            "PETRUCHIO:\n",
            "Come, come, tell me, Somerset: as foolish sou King Edward,\n",
            "Is nothing on the plebate can have them very fair.\n",
            "\n",
            "SABERLI:\n"
          ]
        }
      ]
    }
  ]
}