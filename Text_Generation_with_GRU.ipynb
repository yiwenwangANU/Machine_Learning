{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Generation with GRU.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNVb5e/9alSPOyvvuVsHxsW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yiwenwangANU/Machine_Learning/blob/main/Text_Generation_with_GRU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#loading data"
      ],
      "metadata": {
        "id": "pAVNMuo9U9WK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BshfrTYD6nrx"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lp9hBPsx6ve2",
        "outputId": "083e3e86-7632-4084-957a-b8e813ded13d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1122304/1115394 [==============================] - 0s 0us/step\n",
            "1130496/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(path_to_file, 'rb') as f:\n",
        "  raw_data = f.read().decode('utf-8')"
      ],
      "metadata": {
        "id": "T-go4gqn60gy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "aotSVhFI7Dxl",
        "outputId": "92673341-2b8d-41fc-b260-fe01619937f9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocess the data"
      ],
      "metadata": {
        "id": "sKN4fW5XVDV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = set(raw_data)\n",
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9eVupC-Prxo",
        "outputId": "a5b235d5-7840-4c09-fdd2-1d62f7bf3ff4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"'\", 'd', 'c', 'e', 'j', '-', 'w', 'n', '3', 'f', 'O', 'E', 'p', 'Q', 'm', 'v', ':', '\\n', 'S', 'R', 't', 'Y', 'k', ',', 'x', 'i', 'B', 'K', '$', 'b', 'G', 's', '&', 'W', ';', '?', 'X', 'z', 'h', 'J', 'u', 'C', 'M', '!', 'U', 'D', ' ', 'V', 'F', 'l', 'I', 'N', 'H', 'g', 'r', 'q', 'y', 'A', 'P', 'a', 'Z', 'o', 'T', '.', 'L'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_chars = tf.strings.unicode_split(raw_data, input_encoding='UTF-8') # 'abc' -> tensor ['a', 'b', 'c']\n",
        "all_chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXPdYKIgRgQO",
        "outputId": "1060a852-e3b5-491c-8725-613efe3fb775"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=string, numpy=array([b'F', b'i', b'r', ..., b'g', b'.', b'\\n'], dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = layers.StringLookup(vocabulary=list(vocab)) # tensor ['a', 'b', 'c'] -> tensor [1, 2, 3]"
      ],
      "metadata": {
        "id": "HAxrUm8R7FVH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = layers.StringLookup(vocabulary=encoder.get_vocabulary(), invert=True)"
      ],
      "metadata": {
        "id": "bdwrjaIdTw1a"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoder.get_vocabulary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Br-tcbrTSH-F",
        "outputId": "6efd1a27-d869-4a1d-e99e-771403569f0a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[UNK]', \"'\", 'd', 'c', 'e', 'j', '-', 'w', 'n', '3', 'f', 'O', 'E', 'p', 'Q', 'm', 'v', ':', '\\n', 'S', 'R', 't', 'Y', 'k', ',', 'x', 'i', 'B', 'K', '$', 'b', 'G', 's', '&', 'W', ';', '?', 'X', 'z', 'h', 'J', 'u', 'C', 'M', '!', 'U', 'D', ' ', 'V', 'F', 'l', 'I', 'N', 'H', 'g', 'r', 'q', 'y', 'A', 'P', 'a', 'Z', 'o', 'T', '.', 'L']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_ids = encoder(all_chars)\n",
        "all_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9oEsqbiCmA6",
        "outputId": "731094b4-565c-4d76-8271-9cdff4a06141"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([49, 26, 55, ..., 54, 64, 18])>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
        "ids_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWQq5GXKDeUk",
        "outputId": "c68645df-98d6-49ea-e194-299aa7679bb4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100\n",
        "batched_dataset = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "batched_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FnXDstKEXEt",
        "outputId": "27e9c23e-d989-4f77-bf9b-d62ba9e24a22"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=TensorSpec(shape=(101,), dtype=tf.int64, name=None)>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def input_target_split(sequence):\n",
        "  return sequence[:-1], sequence[1:]\n",
        "\n",
        "input_target_split('12345')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aq7iBg_IEfdk",
        "outputId": "adebad19-fde3-4988-9bb7-2d87ce88379a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('1234', '2345')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = batched_dataset.map(input_target_split)\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlSY23LOG21G",
        "outputId": "53ef0eca-70de-419d-a0cb-b9073c8b3ceb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<MapDataset element_spec=(TensorSpec(shape=(100,), dtype=tf.int64, name=None), TensorSpec(shape=(100,), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, target in dataset.take(1):\n",
        "  print(f'Input: {tf.strings.reduce_join(decoder(inputs))}')\n",
        "  print(f'Target: {tf.strings.reduce_join(decoder(target))}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ao1Qt4bvHEc_",
        "outputId": "b72ea600-06f5-4208-afae-8fdaee5a90b1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.batch(64).prefetch(tf.data.AUTOTUNE)\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7K5K1t-gHfe4",
        "outputId": "71d2e233-2eb6-49bc-aee6-579865e98eff"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 100), dtype=tf.int64, name=None), TensorSpec(shape=(None, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvwifegWpL_b",
        "outputId": "e97ce8de-db85-4e68-b0cd-f38f8774e35a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 100), dtype=tf.int64, name=None), TensorSpec(shape=(None, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Bulid the model"
      ],
      "metadata": {
        "id": "DwZfG--hVodR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(encoder.get_vocabulary())\n",
        "embedding_dim = 256\n",
        "rnn_units = 1024"
      ],
      "metadata": {
        "id": "w-3ZL0GiYf2a"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model_0(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "        super(Model_0, self).__init__()\n",
        "        self.embed = layers.Embedding(input_dim=vocab_size,\n",
        "                                      output_dim=embedding_dim)\n",
        "        self.gru = layers.GRU(units=rnn_units, \n",
        "                              return_sequences=True,\n",
        "                              return_state=True)\n",
        "        self.dense = layers.Dense(vocab_size)\n",
        "\n",
        "    def call(self, inputs, return_state=False, state=None):\n",
        "        x = self.embed(inputs)\n",
        "        if(state==None):\n",
        "          state=self.gru.get_initial_state(x)\n",
        "        \n",
        "        x, state = self.gru(x, initial_state=state)\n",
        "        output = self.dense(x)\n",
        "\n",
        "        if(return_state==True): \n",
        "          return output, state\n",
        "        else:\n",
        "          return output"
      ],
      "metadata": {
        "id": "5epX3NIHVrws"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model_0(vocab_size, embedding_dim, rnn_units)"
      ],
      "metadata": {
        "id": "XnsNTgOilRUc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_sample, _ in dataset.take(1):\n",
        "  print(tf.strings.reduce_join(decoder(input_sample[0])))\n",
        "  sample = tf.squeeze(tf.random.categorical(model(input_sample)[0], 1))\n",
        "  print(tf.strings.reduce_join(decoder(sample)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uA8-pFU2owph",
        "outputId": "39b741e4-1c73-4441-933c-5ba264fe330a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou', shape=(), dtype=string)\n",
            "tf.Tensor(b\"AalXa-sA-o lG?k$EZVtge.o!MKQ-mJWflV[UNK]-oOadpM.pn;\\n[UNK]aB,tMeVc-R,LTOMlwmhgI'c:VN!z,s\\n[UNK]mNlLqTWGhu:E'FX-x[UNK]U\", shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam())"
      ],
      "metadata": {
        "id": "aISIZzWou36I"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(dataset,\n",
        "                  epochs=20)"
      ],
      "metadata": {
        "id": "jPmA0sAdwHJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_one_step(model=model, inputs='ROMEO:', state=None):\n",
        "  inputs = tf.expand_dims(  #(1, seq_len)\n",
        "      encoder(  #(seq_len)\n",
        "          tf.strings.unicode_split(inputs, input_encoding='UTF-8')), #(seq_len,)\n",
        "                          axis=0)\n",
        "\n",
        "  pred, state = model(inputs, return_state=True, state=state) #(1, seq_len, vocab)\n",
        "  pred = tf.random.categorical( #(seq_len, 1)\n",
        "      tf.squeeze(pred, axis=[0]), #(seq_len, vocab)\n",
        "      1) \n",
        "  pred = tf.squeeze( #()\n",
        "      decoder(  #(1)\n",
        "              tf.squeeze(pred, axis=[-1])[-1:])) #(seq_len) (1)\n",
        "  return pred, state\n",
        "\n",
        "predict_one_step(inputs=':')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "092cEkyJw3gi",
        "outputId": "4183a64e-da8e-4cf2-b241-aabc1e6b6842"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=string, numpy=b'\\n'>,\n",
              " <tf.Tensor: shape=(1, 1024), dtype=float32, numpy=\n",
              " array([[ 0.10679512,  0.6995838 , -0.72328156, ..., -0.37781325,\n",
              "          0.36539927,  0.9411402 ]], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_prediction(steps=1000, ininial_inputs='ROMEO:'):\n",
        "  state=None\n",
        "  next_one = ininial_inputs\n",
        "  output = [next_one]\n",
        "  for i in range(steps):\n",
        "    next_one, state = predict_one_step(model=model, inputs=next_one, state=state)\n",
        "    output.append(next_one)\n",
        "  return tf.strings.reduce_join(output)\n",
        "\n",
        "preds = make_prediction()"
      ],
      "metadata": {
        "id": "10DNL8A0_Gv7"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(preds.numpy().decode('utf-8'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yF71H1d_CIax",
        "outputId": "6f1dd533-9a02-4770-c5e1-2326e6932e27"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "Know, sir, 'this meanure's tail and old Citizen:\n",
            "It was the duke's nurs? Your father hath heard\n",
            "As he bears himself to make her tears, and such as I swear.\n",
            "\n",
            "MENENIUS:\n",
            "Romeo sly?\n",
            "\n",
            "BAPTISTA:\n",
            "Marry, sir: she you misthrift or Towards him;\n",
            "For that I might it yourself; for, surely,\n",
            "Trade immortafts, believe it,\n",
            "And herer Vorting. O, he prayed before, father, ho!\n",
            "\n",
            "KATHARINA:\n",
            "For thy love dast: here, sir; heck,\n",
            "But such a stumbling backful man.\n",
            "\n",
            "PROSPERO:\n",
            "Thus fly elesced sly.\n",
            "\n",
            "GREMIO:\n",
            "Farewell.\n",
            "\n",
            "BIONDELLO:\n",
            "What shame? and how my hearts! cheerly?\n",
            "\n",
            "wRONH:\n",
            "Peace, tirm! here let him sleeping withal.\n",
            "Tell me, modest mine unholy watches.\n",
            "\n",
            "PROSPERO:\n",
            "She's even see her forth to pierce itself.\n",
            "Help Sister and his love unto it.\n",
            "\n",
            "KATHARINA:\n",
            "The seay of man.\n",
            "\n",
            "RUKE VINCENTIO:\n",
            "Thy son is this Pidisch'd it cleak--\n",
            "The vessen begin of misery;'s shame,--go,\n",
            "Nor the best friend, it hath sent\n",
            "forth of change purpose.\n",
            "\n",
            "PROSPERO:\n",
            "Thou art a villain. When, Camillo, Most nobles: he is myself: but you have scratch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ea1dCdwCMN8g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}